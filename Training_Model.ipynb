{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Training_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBfaryOgQ_mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "import re, string\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.preprocessing import sequence\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzxBHOcwQ_my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create dataframe from csv data\n",
        "df = pd.read_csv('export_dataframe.csv', error_bad_lines=False, na_values=['nan'])\n",
        "text = df['Synopsis']\n",
        "target = df['Summary']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L87CjOBbQ_m0",
        "colab_type": "code",
        "outputId": "80d067c5-93df-4651-ce21-93de4e5b3ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "#Create the dataframe we are working with and drop some nan rows\n",
        "df = pd.DataFrame({'Synopsis':text, 'Summary':target}, dtype='str')\n",
        "\n",
        "df=df[df.Summary != 'nan']\n",
        "df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Synopsis</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
              "      <td>harper lee consid book simpl love story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The year 1984 has come and gone, but George Or...</td>\n",
              "      <td>deni novel hold imagin generations power admon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Alternate Cover Edition ISBN: 0743273567 (ISBN...</td>\n",
              "      <td>stori fabul wealthi jay gatsbi new love beauti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Harry Potter's life is miserable. His parents ...</td>\n",
              "      <td>harri potter life miserable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>George Orwell's timeless and timely allegorica...</td>\n",
              "      <td>anim farm published stalinist russia seen target</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Ballu  is a gangster who is arrested by Inspec...</td>\n",
              "      <td>ram show compass ballu tri provid inform lead ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>The central figure of the film is represented ...</td>\n",
              "      <td>scienc use brain art use brain heart</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Set in 2003, Huck Cheever  is a young and tale...</td>\n",
              "      <td>billi older sister suzann warn huck hustl 10 c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>The Namesake depicts the struggles of Ashoke a...</td>\n",
              "      <td>short after gogol vacat maxin family ashok dies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>Bobby Taylor ([[Robert Townsend  is a middle c...</td>\n",
              "      <td>practic line bathroom younger brother stevi wa...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9606 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Synopsis                                            Summary\n",
              "0      The unforgettable novel of a childhood in a sl...            harper lee consid book simpl love story\n",
              "1      The year 1984 has come and gone, but George Or...  deni novel hold imagin generations power admon...\n",
              "2      Alternate Cover Edition ISBN: 0743273567 (ISBN...  stori fabul wealthi jay gatsbi new love beauti...\n",
              "3      Harry Potter's life is miserable. His parents ...                        harri potter life miserable\n",
              "4      George Orwell's timeless and timely allegorica...   anim farm published stalinist russia seen target\n",
              "...                                                  ...                                                ...\n",
              "9996   Ballu  is a gangster who is arrested by Inspec...  ram show compass ballu tri provid inform lead ...\n",
              "9997   The central figure of the film is represented ...               scienc use brain art use brain heart\n",
              "9998   Set in 2003, Huck Cheever  is a young and tale...  billi older sister suzann warn huck hustl 10 c...\n",
              "9999   The Namesake depicts the struggles of Ashoke a...    short after gogol vacat maxin family ashok dies\n",
              "10000  Bobby Taylor ([[Robert Townsend  is a middle c...  practic line bathroom younger brother stevi wa...\n",
              "\n",
              "[9606 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TwQkO5WQ_m3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Method for cleaning the synopsis text data\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = ' '.join([w for w in text.split() if w not in ENGLISH_STOP_WORDS])\n",
        "    return text\n",
        "\n",
        "df['Synopsis'] = df['Synopsis'].apply(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SaEWtFxQ_m5",
        "colab_type": "code",
        "outputId": "118c65cb-4002-47b7-929b-8132a6ad4334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#method for cleaning summary text data\n",
        "def clean_title(title):\n",
        "    title = str(title)\n",
        "    title = title.lower()\n",
        "    title = re.sub('\\s+', ' ', title)\n",
        "    title = title.translate(str.maketrans('', '', string.punctuation))\n",
        "    title = ' '.join([w for w in title.split() if w not in ENGLISH_STOP_WORDS])\n",
        "    return title\n",
        "\n",
        "df['CleanTitle'] = df['Summary'].apply(clean_title)\n",
        "\n",
        "#Here we add start and end to the targets so we know when the string stops and padding begins for later\n",
        "df['CleanTitle'] = df['CleanTitle'].apply(lambda x : '_START_ '+ x + ' _END_')\n",
        "print(df['CleanTitle'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0        _START_ harper lee consid book simpl love stor...\n",
            "1        _START_ deni novel hold imagin generations pow...\n",
            "2        _START_ stori fabul wealthi jay gatsbi new lov...\n",
            "3                _START_ harri potter life miserable _END_\n",
            "4        _START_ anim farm published stalinist russia s...\n",
            "                               ...                        \n",
            "9996     _START_ ram compass ballu tri provid inform le...\n",
            "9997     _START_ scienc use brain art use brain heart _...\n",
            "9998     _START_ billi older sister suzann warn huck hu...\n",
            "9999     _START_ short gogol vacat maxin family ashok d...\n",
            "10000    _START_ practic line bathroom younger brother ...\n",
            "Name: CleanTitle, Length: 9606, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7M-ks6RQ_m7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Just train test split, test size of \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Synopsis'], df['CleanTitle'], test_size=0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oqSckHGQ_m9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(df['Synopsis'])\n",
        "\n",
        "#Some globals required to maintain size for strings in and out of the model\n",
        "max_text_length = 125\n",
        "max_target_length = 20\n",
        "\n",
        "#convert each sentence into an array of integer representations for the words\n",
        "x_tr    =   x_tokenizer.texts_to_sequences(df['Synopsis']) \n",
        "x_val   =   x_tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "#we are padding 0 here to the sequence so they are all the same size sequence\n",
        "x_tr    =   sequence.pad_sequences(x_tr,  maxlen=max_text_length, padding='post') \n",
        "x_val   =   sequence.pad_sequences(x_val, maxlen=max_text_length, padding='post')\n",
        "\n",
        "#Total number of different words in our X set\n",
        "x_vocab_size   =  len(x_tokenizer.word_index) +1\n",
        "\n",
        "#Repeat the same as above but in the Y set\n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(df['CleanTitle'])\n",
        "y_tr = y_tokenizer.texts_to_sequences(df['CleanTitle'])\n",
        "y_val = y_tokenizer.texts_to_sequences(y_test)\n",
        "y_tr = sequence.pad_sequences(y_tr, maxlen=max_target_length, padding='post')\n",
        "y_val = sequence.pad_sequences(y_val, maxlen=max_target_length, padding='post')\n",
        "y_vocab_size   =  len(y_tokenizer.word_index) +1\n",
        "\n",
        "#Reshaping data to fit in the format that the RNN needs (3 Dimensions)\n",
        "xtr = x_tr.reshape(x_tr.shape[0],x_tr.shape[1],1)\n",
        "xval = x_val.reshape(x_val.shape[0],x_val.shape[1],1)\n",
        "ytr = y_tr.reshape(y_tr.shape[0],y_tr.shape[1],1)\n",
        "yval = y_val.reshape(y_val.shape[0],y_val.shape[1],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evF8_nQ7Q_nB",
        "colab_type": "code",
        "outputId": "c79dead7-9427-4e45-991c-3a0db414a002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "latentdim = 500\n",
        "#Encoding input layer\n",
        "enc_inputs = Input(shape=(max_text_length,))\n",
        "\n",
        "#Encoding word embedding layer\n",
        "enc_emb = Embedding(x_vocab_size, latentdim, trainable=True)\n",
        "\n",
        "#Use the encoders embedding outputs as inputs for the encoding side LSTM\n",
        "temp = enc_emb(enc_inputs)\n",
        "enc_out, state_h, state_c = LSTM(latentdim,return_state=True,return_sequences=True)(temp)\n",
        "\n",
        "enc_states = [state_h, state_c]\n",
        "#enc_states are the states from the LSTM on enc side that we will use to decode and predict"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j28aRrYQ_nC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Decoding input layer\n",
        "dec_inputs = Input(shape=(None,))\n",
        "#Decoding word embedding layer\n",
        "dec_emb = Embedding(y_vocab_size, latentdim, trainable=True)\n",
        "\n",
        "#Same as in encoding we need to maintain the states so we pass the embedding layer into an LSTM\n",
        "temp = dec_emb(dec_inputs)\n",
        "dec_lstm = LSTM(latentdim, return_sequences=True, return_state=True)\n",
        "\n",
        "dec_out, dec_state_h, dec_stat_c = dec_lstm(temp,initial_state=enc_states) #encoder states used here\n",
        "\n",
        "#Dense layer to turn our matrix into a usable output array\n",
        "dec_dense = Dense(y_vocab_size, activation='softmax')\n",
        "dec_out = dec_dense(dec_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AqKBS8EQ_nE",
        "colab_type": "code",
        "outputId": "54552a18-37bd-4892-995a-ed7710ba656b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "#Creating the model object with a printout to help visualize the connections\n",
        "model = Model([enc_inputs,dec_inputs], dec_out)\n",
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 125)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 125, 500)     48361500    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 500)    18539000    input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 125, 500), ( 2002000     embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 500),  2002000     embedding_3[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 37078)  18576078    lstm_3[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 89,480,578\n",
            "Trainable params: 89,480,578\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNhcSQaFQ_nG",
        "colab_type": "code",
        "outputId": "847b396d-b8b8-430f-82bf-ca948133d3f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Training the model, batch_size and epochs can be adjusted for your environment and were selected through trial and error.\n",
        "# epochs is the number of times the models is trained on the data\n",
        "# batch_size is the number of rows fed to the model at a time, higher batch_size requires more memory but will train faster\n",
        "modelout = model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,batch_size=256, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 9606 samples, validate on 1922 samples\n",
            "Epoch 1/50\n",
            "9606/9606 [==============================] - 54s 6ms/step - loss: 6.0268 - val_loss: 5.8621\n",
            "Epoch 2/50\n",
            "9606/9606 [==============================] - 54s 6ms/step - loss: 5.9066 - val_loss: 5.7856\n",
            "Epoch 3/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 5.8244 - val_loss: 5.7264\n",
            "Epoch 4/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 5.7407 - val_loss: 5.5902\n",
            "Epoch 5/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 5.6344 - val_loss: 5.4739\n",
            "Epoch 6/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 5.5351 - val_loss: 5.3848\n",
            "Epoch 7/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 5.4359 - val_loss: 5.2493\n",
            "Epoch 8/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 5.3349 - val_loss: 5.1550\n",
            "Epoch 9/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 5.2314 - val_loss: 5.0340\n",
            "Epoch 10/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 5.1308 - val_loss: 4.9413\n",
            "Epoch 11/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 5.0294 - val_loss: 4.8210\n",
            "Epoch 12/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 4.9849 - val_loss: 4.8356\n",
            "Epoch 13/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 4.9235 - val_loss: 4.6923\n",
            "Epoch 14/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 4.7975 - val_loss: 4.5593\n",
            "Epoch 15/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 4.6655 - val_loss: 4.4360\n",
            "Epoch 16/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 4.5588 - val_loss: 4.3145\n",
            "Epoch 17/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 4.4767 - val_loss: 4.2093\n",
            "Epoch 18/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 4.3285 - val_loss: 4.1010\n",
            "Epoch 19/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 4.2114 - val_loss: 3.9776\n",
            "Epoch 20/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 4.1016 - val_loss: 3.8761\n",
            "Epoch 21/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 3.9926 - val_loss: 3.7421\n",
            "Epoch 22/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 3.8848 - val_loss: 3.6484\n",
            "Epoch 23/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 3.7671 - val_loss: 3.5258\n",
            "Epoch 24/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 3.6630 - val_loss: 3.4256\n",
            "Epoch 25/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 3.5588 - val_loss: 3.3208\n",
            "Epoch 26/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 3.4540 - val_loss: 3.2097\n",
            "Epoch 27/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 3.3460 - val_loss: 3.1127\n",
            "Epoch 28/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 3.2397 - val_loss: 3.0157\n",
            "Epoch 29/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 3.1354 - val_loss: 2.9187\n",
            "Epoch 30/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 3.0287 - val_loss: 2.8220\n",
            "Epoch 31/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 2.9346 - val_loss: 2.7281\n",
            "Epoch 32/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 2.8383 - val_loss: 2.6207\n",
            "Epoch 33/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 2.7396 - val_loss: 2.5512\n",
            "Epoch 34/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 2.6500 - val_loss: 2.4474\n",
            "Epoch 35/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 2.5561 - val_loss: 2.3569\n",
            "Epoch 36/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 2.4719 - val_loss: 2.2712\n",
            "Epoch 37/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 2.3838 - val_loss: 2.1795\n",
            "Epoch 38/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 2.2954 - val_loss: 2.1130\n",
            "Epoch 39/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 2.2133 - val_loss: 2.0259\n",
            "Epoch 40/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 2.1300 - val_loss: 1.9592\n",
            "Epoch 41/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 2.0481 - val_loss: 1.8697\n",
            "Epoch 42/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 1.9725 - val_loss: 1.8049\n",
            "Epoch 43/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 1.8835 - val_loss: 1.7243\n",
            "Epoch 44/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 1.8033 - val_loss: 1.6605\n",
            "Epoch 45/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 1.7280 - val_loss: 1.5865\n",
            "Epoch 46/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 1.6480 - val_loss: 1.5124\n",
            "Epoch 47/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 1.5721 - val_loss: 1.4186\n",
            "Epoch 48/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 1.4972 - val_loss: 1.3754\n",
            "Epoch 49/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 1.4209 - val_loss: 1.2894\n",
            "Epoch 50/50\n",
            "9606/9606 [==============================] - 55s 6ms/step - loss: 1.3492 - val_loss: 1.2242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRtmuIuyqTiR",
        "colab_type": "code",
        "outputId": "5d01b5e7-0e9c-4783-eaa1-9e8979e26fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "#Visualization of models performance over # of epochs\n",
        "from matplotlib import pyplot \n",
        "pyplot.plot(modelout.history['loss'], label='train') \n",
        "pyplot.plot(modelout.history['val_loss'], label='test') \n",
        "pyplot.legend() \n",
        "pyplot.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA02dXYtS5I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save the model for use in our demo and to prevent us from having to train every time which can take a long time\n",
        "import os\n",
        "os.makedirs('./model', exist_ok=True)\n",
        "model.save('./model/model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEgvkHOaQ_nI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}